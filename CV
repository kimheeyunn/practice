import os
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter

# 텐서보드 로그 디렉토리 설정 및 생성
log_dir = './runs/mnist_cnn_experiment'
if not os.path.exists(log_dir):
    os.makedirs(log_dir)

# MNIST 데이터 로드를 위한 트랜스폼 정의
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# 훈련 데이터와 테스트 데이터 로드

train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('./data', train=False, transform=transform)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        # Convolution Layer 1: 5x5 filter 10개
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
        # Max pooling Layer 1: 2x2에서 가장 큰 값 선택
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        # Convolution Layer 2: 5x5 filter 20개
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
        # Max pooling Layer 2: 2x2에서 가장 큰 값 선택
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        # Fully Connected Layer 1: In → 50dim으로 축소
        self.fc1 = nn.Linear(in_features=320, out_features=50)  # 320 comes from the shape after the two convolution and pooling layers
        # Fully Connected Layer 2: In → 10dim으로 축소
        self.fc2 = nn.Linear(in_features=50, out_features=10)

    def forward(self, x):
        # Convolution Layer 1
        x = F.relu(self.conv1(x))
        # Max pooling Layer 1
        x = self.pool1(x)
        # Convolution Layer 2
        x = F.relu(self.conv2(x))
        # Max pooling Layer 2
        x = self.pool2(x)
        # Reshape the tensor for the fully connected layer
        x = x.view(-1, 320)  # 320 comes from the shape after the two convolution and pooling layers
        # Fully Connected Layer 1
        x = F.relu(self.fc1(x))
        # Fully Connected Layer 2
        x = self.fc2(x)
        return F.log_softmax(x, dim=1)

# 모델, 손실 함수, 최적화 알고리즘 설정
model = CNN()
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.7)

# TensorBoard writer 초기화
writer = SummaryWriter(log_dir)

# -------------------------------
# 1. CNN 모델 사전 학습
# -------------------------------
def train(model, device, train_loader, optimizer, epoch):  # train 함수 추가
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        writer.add_scalar('Loss/train', loss.item(), epoch * len(train_loader) + batch_idx)
        if batch_idx % 10 == 0:
            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '
                  f'({100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

def test(model, device, test_loader, epoch):  # test 함수 추가
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target).item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()

        test_loss /= len(test_loader.dataset)
        accuracy = 100. * correct / len(test_loader.dataset)
        writer.add_scalar('Loss/test', test_loss, epoch)
        writer.add_scalar('Accuracy/test', accuracy, epoch)
        print(f'\nTest set: Average loss: {test_loss:.4f}, '
              f'Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\n')
        
def pretrain(model, train_loader, optimizer, epochs):
    for epoch in range(1, epochs + 1):
        train(model, device, train_loader, optimizer, epoch)
        test(model, device, test_loader, epoch)
        save_model(model, epoch)

# 5 에폭 동안 모델 사전 학습
pretrain(model, train_loader, optimizer, epochs=5)

# -------------------------------
# 2. 전이 학습: 짝수/홀수 분류기 만들기
# -------------------------------

# 2-1. 타겟 데이터 변환 (0~9) → 짝수/홀수
def transform_target(target):
    return torch.tensor(target % 2, dtype=torch.long)

# 2-2. 마지막 Layer 변환 (짝수/홀수를 분류하도록 변환)
model.fc2 = nn.Linear(in_features=50, out_features=2)  # 이진 분류기로 변환

# 2-3. FC Layer를 제외한 나머지 층을 freeze
def freeze_layers(model, freeze_fc1=True):
    for param in model.parameters():
        param.requires_grad = False
    model.conv1.weight.requires_grad = True
    model.conv1.bias.requires_grad = True
    model.conv2.weight.requires_grad = True
    model.conv2.bias.requires_grad = True
    model.fc1.weight.requires_grad = not freeze_fc1
    model.fc1.bias.requires_grad = not freeze_fc1

# -------------------------------
# 2-4. CNN만 Freeze한 경우
# -------------------------------
model.load_state_dict(torch.load('models/mnist_cnn_model_epoch_5.pth'))  # 저장된 CNN 모델 불러오기
freeze_layers(model, freeze_fc1=False)  # FC1까지 freeze하지 않음

# 새로운 optimizer를 사용하여 전이 학습 진행
optimizer_transfer_cnn_only = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
for epoch in range(1, 6):
    train(model, device, train_loader, optimizer_transfer_cnn_only, epoch)
    test(model, device, test_loader, epoch)

# 모델 저장
save_model(model, 'transfer_cnn_only')

# -------------------------------
# 2-5. FC1까지 Freeze한 경우
# -------------------------------
model.load_state_dict(torch.load('models/mnist_cnn_model_epoch_5.pth'))  # 저장된 CNN 모델 불러오기
freeze_layers(model, freeze_fc1=True)  # FC1까지 freeze

# 새로운 optimizer를 사용하여 전이 학습 진행
optimizer_transfer_fc1 = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)
for epoch in range(1, 6):
    train(model, device, train_loader, optimizer_transfer_fc1, epoch)
    test(model, device, test_loader, epoch)

# 모델 저장
save_model(model, 'transfer_fc1')

# TensorBoard 닫기
writer.close()
